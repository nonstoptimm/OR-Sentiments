cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir, encoding = "ANSI"))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- Corpus(DirSource(directory = s.dir))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- VCorpus(DirSource(directory = s.dir), readerControl = list(reader=readPlain))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- VCorpus(DirSource(directory = s.dir), readerControl = list(reader=readPlain))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
list.files(input-data/speeches)
list.files("input-data/speeches")
filelist <- list.files("input-data/speeches")
readEEM(filelist)
readtext(filelist)
readtext(filelist)
library(readtext)
library("readtext")
readLines(filelist)
lappy(filelist, readLines)
lapply(filelist, readLines)
lapply(filelist, read.file)
library("read.file")
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
lapply(filelist, read.table)
library("read.table")
library("data.table")
install.packages("data.table")
library("data.table")
lapply(filelist, read.table)
list.files("input-data/speeches")
list.files("input-data/speeches", full.names = TRUE)
filelist <- list.files("input-data/speeches", full.names = TRUE)
lapply(filelist, read.table)
lapply(filelist, fread)
filelist <- list.files("input-data/speeches", full.names = TRUE)
lapply(filelist, fread)
filelist <- list.files("input-data/speeches", full.names = TRUE)
df <- lapply(filelist, fread)
library("data.table")
install.packages("data.table")
install.packages("data.table")
library(data.table)
filelist <- list.files("input-data/speeches", full.names = TRUE)
df <- lapply(filelist, fread)
# Set options
options(stringsAsFactors = FALSE)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
filelist <- list.files("input-data/speeches", full.names = TRUE)
df <- lapply(filelist, fread)
# clean text
cleanCorpus <- function(corpus) {
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus, stripWhitespace)
corpus.tmp <- tm_map(corpus, tolower)
corpus.tmp <- tm_map(corpus, removeWords, stopwords("english"))
return(corpus.tmp)
}
# build TDM
generateTDM <- function(cand, path){
s.dir <- sprintf("%s/%s", path, candidates)
s.cor <- VCorpus(DirSource(directory = s.dir), readerControl = list(reader=readPlain))
s.cor.cl <- CleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.7)
result <- list(name = cand, tdm = s.tdm)
}
tdm <- lapply(candidates, generateTDM, path = pathname)
candidates <- c("bush", "obama")
pathname <- "input-data/speeches"
filelist <- list.files("input-data/speeches", full.names = TRUE)
df <- lapply(filelist, fread)
lapply(libraries, require, character.only = TRUE)
filelist <- list.files("input-data/speeches", full.names = TRUE)
df <- lapply(filelist, fread)
lapply(libraries, require, character.only = TRUE)
libraries <- c("tm", "dplyr", "class", "devtools", "tidytext", "ggplot2", "qdap")
lapply(libraries, require, character.only = TRUE)
install.packages("ggplot2")
install.packages("qdap")
install.packages("tidytext")
libraries <- c("tm", "dplyr", "tidytext", "ggplot2", "qdap")
lapply(libraries, require, character.only = TRUE)
library("qdap")
install.packages("rJava")
library("rJava")
install.packages("rJava")
library("qdap")
library("rJava")
install.packages("rJava")
library("rJava")
options('java.home')
library('java.home')
rm.packages()
remove.packages(rJava)
remove.packages("rJava")
options('java.home')
options("java.home"="/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre")
options("java.home"="/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home/jre")
options('java.home')
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk1.8.0_71.jdk/Contents/Home')
Sys.setenv(LD_LIBRARY_PATH='$JAVA_HOME/jre/lib/server')
install.packages('rJava')
library("rJava")
library("qdap")
libraries <- c("tm", "dplyr", "tidytext", "ggplot2", "qdap")
lapply(libraries, require, character.only = TRUE)
metadata <- ndjson::stream_in("import-data/electronic_meta.json")
library("ndjson")
install.packages("ndjson")
library("ndjson")
metadata <- ndjson::stream_in("import-data/electronic_meta.json")
metadata <- ndjson::stream_in("import-data/raw_electronics_meta.json")
metadata <- ndjson::stream_in("input-data/raw_electronics_meta.json")
names(metadata)
as.tibble(metadata)
install.packages("tibble")
library("tibble")
as.tibble(metadata)
rawdata <- ndjson::stream_in("input-data/raw_electronics_reviews.json")
names(rawdata)
head(rawdata)
names(rawdata)
rawdata$reviewText[5]
rawdata$asin[5]
metadata[, asin == "0439886341"]
select(metadata, asin == "0439886341")
select(metadata, asin == "0439886341")
metadata[metadata$asin == 0439886341, ]
metadata[metadata$asin == "0439886341", ]
metadata[metadata$asin == "0439886341", title ]
rawdata_subset <- rawdata[1:1000, ]
names(rawdata_subset)
rawdata_subset[, -unixReviewTime]
names(rawdata_subset[, -unixReviewTime])
subset(rawdata_subset, select = -unixReviewTime)
rawdata_subset <- subset(rawdata_subset, select = -unixReviewTime)
group_by(rawdata_subset, asin)
review_corpus <- VCorpus(VectorSource(rawdata_subset$reviewTime))
clean_corpus(review_corpus)
# Function for Corpus Cleaning
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en"))
return(corpus)
}
# Function for Corpus Cleaning
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
return(corpus)
}
clean_corpus(review_corpus)
clean_corp <- clean_corpus(review_corpus)
stopwords("en")
clean_corp[[227]][1]
review_corpus <- VCorpus(VectorSource(rawdata_subset$reviewText))
names(review_corpus)
names(rawdata_subset)
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
return(corpus)
}
clean_corp <- clean_corpus(review_corpus)
review_dtm <- DocumentTermMatrix(clean_corp)
review_m <- as.matrix(review_dtm)
review_m[148:150, 2587:2590]
tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
mean(rawdata_subset$overall)
summary(rawdata_subset$overall)
table(rawdata_subset$overall)
table(rawdata_subset$helpful.1)
summary(rawdata_subset$helpful.1)
summary(rawdata_subset$helpful.0)
table(rawdata_subset$helpful.0)
mean(rawdata_subset$helpful.0)
mean(rawdata_subset$helpful.1)
review_tdm <- TermDocumentMatrix(clean_corp)
review_m <- as.matrix(review_tdm)
# Rowsums
chardonnay_words <- rowSums(review_m)
chardonnay_words <- sort(chardonnay_words, decreasing = TRUE)
review_words <- rowSums(review_m)
review_m <- as.matrix(review_tdm)
# Rowsums
review_words <- rowSums(review_m)
review_tdm <- TermDocumentMatrix(clean_corp)
clean_corp <- clean_corpus(review_corpus)
rawdata_subset <- rawdata[1:1000, ]
rm(slam_url)
rm(pathname)
rm(filelist)
rm(candidates)
write.csv
write.csv(rawdata_subset, file = "write.csv")
rawdata <- ndjson::stream_in("input-data/raw_electronics_reviews.json")
metadata <- ndjson::stream_in("input-data/raw_electronics_meta.json")
rawdata_subset <- rawdata[1:5000, ]
write.csv(rawdata_subset, file = "write.csv")
review_corpus <- VCorpus(VectorSource(rawdata_subset$reviewText))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
return(corpus)
}
clean_corp <- clean_corpus(review_corpus)
review_dtm <- DocumentTermMatrix(clean_corp)
# Store as Term Document Matrix (for the word cloud)
review_tdm <- TermDocumentMatrix(clean_corp)
review_dtm_m <- as.matrix(review_dtm)
review_words <- rowSums(review_tdm_m)
review_words <- sort(review_words, decreasing = TRUE)
# Dataframe for the Word Cloud
review_freqs <- data.frame(term = names(review_words), num = review_words)
# Create the Wordcloud
wordcloud(review_freqs$term, review_freqs$num, max.words = 50, color = "blue")
review_words <- rowSums(review_tdm_m)
review_tdm <- TermDocumentMatrix(clean_corp)
review_tdm_m <- as.matrix(review_tdm)
review_words <- rowSums(review_tdm_m)
review_words <- sort(review_words, decreasing = TRUE)
# Dataframe for the Word Cloud
review_freqs <- data.frame(term = names(review_words), num = review_words)
library(wordcloud)
wordcloud(review_freqs$term, review_freqs$num, max.words = 50, color = "blue")
wordcloud(review_freqs$term, review_freqs$num, max.words = 70, color = "blue")
tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
bigram_dtm <- DocumentTermMatrix(clean_corp, control = list(tokenize = tokenizer))
