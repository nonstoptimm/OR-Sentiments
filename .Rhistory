input$reviewYear <- format(input$reviewTime, format="%Y")
# Filter for Brand
input <- input %>% filter(brand %in% brandSelect$brand)
# Aggregate
aggregated <- input %>%
group_by(brand, reviewYear, reviewMonth, mainTopic) %>%
summarise(AvgScore = mean(scoreNN), AvgStar = mean(overall), n=n()) %>%
ungroup()
# Glue date back together
aggregated$date <- paste(aggregated$reviewYear, aggregated$reviewMonth, sep = "-")
# and remove $year + $month
aggregated$reviewYear <- aggregated$reviewMonth <- NULL
# Return aggregated data
return(aggregated)
}
# Apply createTopicSeries-function
topicSeriesCellphone <- createTopicSeries(merged_topic_cellphone, top10brands_cellphone)
# PLOT TIME SERIES FOR AVERAGE SENTIMENT SCORE
plotTopicSeries <- function(input, brandSelect, brandText, begin, end, ylim, labels){
# Filter for the products and time range
input <- input %>%
filter(brand == brandSelect, date >= begin & date <= end)
input$date <- as.factor(input$date)
# mainTopic as factor for x-axis
input$mainTopic <- as.factor(input$mainTopic)
# Plot data
ggplot(data = input, aes(x = date, group = mainTopic, color = mainTopic)) +
geom_line(aes(y = AvgScore), size = 1) +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(y = "Average Sentiment", x = "Time Period") +
scale_colour_hue(name = "MainTopic", labels = labels) +
theme(text = element_text(size = 12, family = "LM Roman 10")) +
ylim(ylim)
}
png("8_TimeSeriesSoA-Apple.png", res = 300, units="in", width=7, height=3)
plotTopicSeries(topicSeriesCellphone, "apple", "Apple (Cellphones)", "2012-01", "2013-12", c(-1.7,1.5), c("Purchase", "Software", "Hardware", "Brand Attitude", "Battery Life")) +
# Add lines for product launch dates
# iPhone 5
geom_vline(aes(xintercept = which(levels(date) %in% "2012-10")), color="red") +
geom_label(stat = 'identity', aes(x = which(levels(date) %in% "2012-10"), label = "Launch Apple iPhone 5", y = 0), color = "red", angle = 90, vjust = -5, hjust = 0, family = "LM Roman 10")
dev.off()
png("8_TimeSeriesSoA-Samsung.png", res = 300, units="in", width=7, height=3)
plotTopicSeries(topicSeriesCellphone, "samsung", "Samsung (Cellphones)", "2012-01", "2013-12", c(-1.7,1.5), c("Purchase", "Software", "Hardware", "Brand Attitude", "Battery Life")) +
# Samsung S3
geom_vline(aes(xintercept = which(levels(date) %in% "2012-05")), color="blue") +
geom_label(stat = 'identity', aes(x = which(levels(date) %in% "2012-05"), label = "Launch Samsung S3", y = 0), color= "blue", angle = 90, vjust = -5, hjust = 0, family = "LM Roman 10")
dev.off()
png("8_TimeSeriesSoA-Apple.png", res = 300, units="in", width=7, height=3)
plotTopicSeries(topicSeriesCellphone, "apple", "Apple (Cellphones)", "2012-01", "2013-12", c(-1.7,1.5), c("Purchase", "Software", "Hardware", "Brand Attitude", "Battery Life")) +
# Add lines for product launch dates
# iPhone 5
geom_vline(aes(xintercept = which(levels(date) %in% "2012-10")), color="red") +
geom_label(stat = 'identity', aes(x = which(levels(date) %in% "2012-10"), label = "Launch Apple iPhone 5", y = 0), color = "red", angle = 90, vjust = -3, hjust = 0, family = "LM Roman 10")
dev.off()
png("8_TimeSeriesSoA-Samsung.png", res = 300, units="in", width=7, height=3)
plotTopicSeries(topicSeriesCellphone, "samsung", "Samsung (Cellphones)", "2012-01", "2013-12", c(-1.7,1.5), c("Purchase", "Software", "Hardware", "Brand Attitude", "Battery Life")) +
# Samsung S3
geom_vline(aes(xintercept = which(levels(date) %in% "2012-05")), color="blue") +
geom_label(stat = 'identity', aes(x = which(levels(date) %in% "2012-05"), label = "Launch Samsung S3", y = 0), color= "blue", angle = 90, vjust = -3, hjust = 0, family = "LM Roman 10")
dev.off()
# Apply plotTimeSeries-function
png("8_TimeSeriesProducts.png", res = 300, units="in", width=7, height=3)
plotProductTimeSeries(timeCellphoneProduct, c("Galaxy S3", "iPhone 5"), "Apple iPhone 5 vs. Samsung Galaxy S3", "2012-05", "2013-12", c(-1,1)) +
# Add lines for product launch dates
# iPhone 5
geom_vline(aes(xintercept = which(levels(date) %in% "2012-10")), color = "red") +
geom_label(stat = "identity", aes(x = which(levels(date) %in% "2012-10"), label = "Launch Apple iPhone 5", y = 0), color = "red", angle = 90, vjust = 3, hjust = 0, family = "LM Roman 10")
# Samsung S3
geom_vline(aes(xintercept = which(levels(date) %in% "2012-05")), color = "blue") +
geom_label(stat = "identity", aes(x = which(levels(date) %in% "2012-05"), label = "Launch Samsung S3", y = 0), color= "blue", angle = 90, vjust = -4, hjust = 0, family = "LM Roman 10") +
dev.off()
# Apply plotTimeSeries-function
png("8_TimeSeriesProducts.png", res = 300, units="in", width=7, height=3)
plotProductTimeSeries(timeCellphoneProduct, c("Galaxy S3", "iPhone 5"), "Apple iPhone 5 vs. Samsung Galaxy S3", "2012-05", "2013-12", c(-1,1)) +
# Add lines for product launch dates
# iPhone 5
geom_vline(aes(xintercept = which(levels(date) %in% "2012-10")), color = "red") +
geom_label(stat = "identity", aes(x = which(levels(date) %in% "2012-10"), label = "Launch Apple iPhone 5", y = 0), color = "red", angle = 90, vjust = 3, hjust = 0, family = "LM Roman 10") +
# Samsung S3
geom_vline(aes(xintercept = which(levels(date) %in% "2012-05")), color = "blue") +
geom_label(stat = "identity", aes(x = which(levels(date) %in% "2012-05"), label = "Launch Samsung S3", y = 0), color= "blue", angle = 90, vjust = -4, hjust = 0, family = "LM Roman 10")
dev.off()
rm(list=ls())
# GENERAL DATA IMPORT
# dataImport.R
# Load required packages
library(dplyr)
library(data.table)
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand-filtered.csv"))
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand.csv"))
# IMPORT PREPARED DATASETS WITHOUT RELEVANT WORDS
prep_cellphone_brand <- as_tibble(fread("output/prep_cellphone_brand-filtered.csv"))
rm(prep_cellphone_brand)
set.seed(101)
# TAKE DATA SAMPLE ABOUT 30%, CHOOSE RANDOM LINES
sampleData <- function(input, x){ # x for amount of data
sample <- sample.int(n = nrow(input), size = floor(x*nrow(input)), replace = F)
return(sample)
}
# Apply sampleData-function
sampleCellphone <- sampleData(prep_cellphone_brand, .3)
sampleHeadphone <- sampleData(prep_headphone_brand, .3)
# PULL SAMPLE OF DATASET
sampleHeadphone <- sampleData(prep_headphone_brand, .15)
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
sampleHeadphone <- sampleData(prep_headphone_brand, .1)
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
# MEDIATE DATA
removeXGsw <- function(input){
input %>%
unnest_tokens(word, review) %>% # unnest the reviews to single words
# anti_join(stopword_list, by = c("word" = "value")) %>% # anti-join to predefined stopword list
anti_join(stop_words) %>% # anti-join to predefined stopword list
nest(word) %>% # nest the words again to list items
mutate(review = map(data, unlist), # create review column and glue the terms together again
review = map_chr(review, paste, collapse = " ")) # separate by a blank
}
mediateHeadphone <- removeXGsw(mediateHeadphone)
library(text2vec)
library(xgboost)
library(pdp)
library(dplyr)
library(tidytext)
library(tidyverse)
library(Ckmeans.1d.dp)
trainHeadphone <- mediateHeadphone[1:15000,] # training-data
testHeadphone <- mediateHeadphone[15001:21037,] # test-data
verifyHeadphone <- prep_headphone_brand[40001:50000,] # verification-data
verifyHeadphone <- prep_headphone_brand[15000:20000,] # verification-data
# CREATE VOCABULARY
# Tokenize the movie reviews and create a vocabulary of tokens including document counts
# Mediate Data as input
createVoc <- function(input){
vocab <- create_vocabulary(itoken(input$review, tokenizer = word_tokenizer))
return(vocab)
}
vocabHeadphone <- createVoc(mediateHeadphone)
# BUILD DTM
# Build a document-term matrix using the tokenized review text.
# This returns a dgCMatrix object
createDTM <- function(input, vocab){
dtm <- create_dtm(itoken(input$review, tokenizer = word_tokenizer), vocab_vectorizer(vocab))
return(dtm)
}
dtm_trainHeadphone <- createDTM(trainHeadphone, vocabHeadphone)
dtm_testHeadphone <- createDTM(testHeadphone, vocabHeadphone)
trainScoreHeadphone <- trainHeadphone$scoreNN
testScoreHeadphone <- testHeadphone$scoreNN
xgbMTrainHeadphone <- xgb.DMatrix(dtm_trainHeadphone, label = trainScoreHeadphone)
xgbMTestHeadphone <- xgb.DMatrix(dtm_testHeadphone, label = testScoreHeadphone)
rm(prep_headphone_brand)
watchlistHeadphone <- list(validation = xgbMTestHeadphone, train=xgbMTrainHeadphone)
# Build XGBOOST Model
xgb_params = list(
objective = "reg:linear", # linear regression as a continuous variable has to be predicted
eta = 0.01,
max.depth = 1000)
rm(list=ls())
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand.csv"))
set.seed(101)
# TAKE DATA SAMPLE ABOUT 30%, CHOOSE RANDOM LINES
sampleData <- function(input, x){ # x for amount of data
sample <- sample.int(n = nrow(input), size = floor(x*nrow(input)), replace = F)
return(sample)
}
# Apply sampleData-function
sampleHeadphone <- sampleData(prep_headphone_brand, .1)
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
rm(prep_headphone_brand)
# MEDIATE DATA
removeXGsw <- function(input){
input %>%
unnest_tokens(word, review) %>% # unnest the reviews to single words
# anti_join(stopword_list, by = c("word" = "value")) %>% # anti-join to predefined stopword list
anti_join(stop_words) %>% # anti-join to predefined stopword list
nest(word) %>% # nest the words again to list items
mutate(review = map(data, unlist), # create review column and glue the terms together again
review = map_chr(review, paste, collapse = " ")) # separate by a blank
}
mediateHeadphone <- removeXGsw(mediateHeadphone)
trainHeadphone <- mediateHeadphone[1:15000,] # training-data
testHeadphone <- mediateHeadphone[15001:21037,] # test-data
rm(list=ls())
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand.csv"))
# TAKE DATA SAMPLE ABOUT 30%, CHOOSE RANDOM LINES
sampleData <- function(input, x){ # x for amount of data
sample <- sample.int(n = nrow(input), size = floor(x*nrow(input)), replace = F)
return(sample)
}
# SET SEED
# For reproducible sampling
set.seed(101)
# TAKE DATA SAMPLE ABOUT 30%, CHOOSE RANDOM LINES
sampleData <- function(input, x){ # x for amount of data
sample <- sample.int(n = nrow(input), size = floor(x*nrow(input)), replace = F)
return(sample)
}
sampleHeadphone <- sampleData(prep_headphone_brand, .1)
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
# MEDIATE DATA
removeXGsw <- function(input){
input %>%
unnest_tokens(word, review) %>% # unnest the reviews to single words
# anti_join(stopword_list, by = c("word" = "value")) %>% # anti-join to predefined stopword list
anti_join(stop_words) %>% # anti-join to predefined stopword list
nest(word) %>% # nest the words again to list items
mutate(review = map(data, unlist), # create review column and glue the terms together again
review = map_chr(review, paste, collapse = " ")) # separate by a blank
}
mediateHeadphone <- removeXGsw(mediateHeadphone)
trainHeadphone <- mediateHeadphone[1:15000,] # training-data
testHeadphone <- mediateHeadphone[15001:21037,] # test-data
rm(list=ls())
# SET SEED
# For reproducible sampling
set.seed(101)
# TAKE DATA SAMPLE ABOUT 30%, CHOOSE RANDOM LINES
sampleData <- function(input, x){ # x for amount of data
sample <- sample.int(n = nrow(input), size = floor(x*nrow(input)), replace = F)
return(sample)
}
sampleHeadphone <- sampleData(prep_headphone_brand, .12)
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand.csv"))
sampleHeadphone <- sampleData(prep_headphone_brand, .12)
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
# MEDIATE DATA
removeXGsw <- function(input){
input %>%
unnest_tokens(word, review) %>% # unnest the reviews to single words
# anti_join(stopword_list, by = c("word" = "value")) %>% # anti-join to predefined stopword list
anti_join(stop_words) %>% # anti-join to predefined stopword list
nest(word) %>% # nest the words again to list items
mutate(review = map(data, unlist), # create review column and glue the terms together again
review = map_chr(review, paste, collapse = " ")) # separate by a blank
}
mediateHeadphone <- removeXGsw(mediateHeadphone)
rm(list=ls())
# SET SEED
# For reproducible sampling
set.seed(101)
# TAKE DATA SAMPLE ABOUT 30%, CHOOSE RANDOM LINES
sampleData <- function(input, x){ # x for amount of data
sample <- sample.int(n = nrow(input), size = floor(x*nrow(input)), replace = F)
return(sample)
}
sampleHeadphone <- sampleData(prep_headphone_brand, .1)
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand.csv"))
sampleHeadphone <- sampleData(prep_headphone_brand, .1)
mediateHeadphone <- as_tibble(prep_headphone_brand[sampleHeadphone, ])
# MEDIATE DATA
removeXGsw <- function(input){
input %>%
unnest_tokens(word, review) %>% # unnest the reviews to single words
# anti_join(stopword_list, by = c("word" = "value")) %>% # anti-join to predefined stopword list
anti_join(stop_words) %>% # anti-join to predefined stopword list
nest(word) %>% # nest the words again to list items
mutate(review = map(data, unlist), # create review column and glue the terms together again
review = map_chr(review, paste, collapse = " ")) # separate by a blank
}
mediateHeadphone <- removeXGsw(mediateHeadphone)
trainHeadphone <- mediateHeadphone[1:15000,] # training-data
testHeadphone <- mediateHeadphone[15001:20715,] # test-data
# CREATE VOCABULARY
# Tokenize the movie reviews and create a vocabulary of tokens including document counts
# Mediate Data as input
createVoc <- function(input){
vocab <- create_vocabulary(itoken(input$review, tokenizer = word_tokenizer))
return(vocab)
}
vocabHeadphone <- createVoc(mediateHeadphone)
# BUILD DTM
# Build a document-term matrix using the tokenized review text.
# This returns a dgCMatrix object
createDTM <- function(input, vocab){
dtm <- create_dtm(itoken(input$review, tokenizer = word_tokenizer), vocab_vectorizer(vocab))
return(dtm)
}
dtm_trainHeadphone <- createDTM(trainHeadphone, vocabHeadphone)
dtm_testHeadphone <- createDTM(testHeadphone, vocabHeadphone)
trainScoreHeadphone <- trainHeadphone$scoreNN
testScoreHeadphone <- testHeadphone$scoreNN
xgbMTrainHeadphone <- xgb.DMatrix(dtm_trainHeadphone, label = trainScoreHeadphone)
xgbMTestHeadphone <- xgb.DMatrix(dtm_testHeadphone, label = testScoreHeadphone)
watchlistHeadphone <- list(validation = xgbMTestHeadphone, train=xgbMTrainHeadphone)
# Build XGBOOST Model
xgb_params = list(
objective = "reg:linear", # linear regression as a continuous variable has to be predicted
eta = 0.01,
max.depth = 1000)
# Train the model
trainXGB <- function(train_matrix, xgb_params, watchlist){
xgb_fit <- xgb.train(params = xgb_params, data = train_matrix, nrounds = 10000, watchlist = watchlist, early_stopping_rounds = 20, maximize = FALSE) # with verify process
return(xgb_fit)
}
rm(prep_headphone_brand)
rm(mediateHeadphone)
rm(testHeadphone)
rm(trainHeadphone)
xgbHeadphone <- trainXGB(xgbMTrainHeadphone, xgb_params, watchlistHeadphone)
saveXG(xgbCoffee, "XG_Headphone1")
# SAVE XGBOOST
saveXG <- function(input, filename){
xgb.save(input, paste("output/", filename, sep=""))
}
saveXG(xgbHeadphone, "XG_Headphones1")
# Create Feature Importance Overview
xgbImpVar <- function(input, cols){
importance_vars <- xgb.importance(model = input, feature_names = colnames(cols))
return(importance_vars)
}
importanceHeadphone <- xgbImpVar(xgbHeadphone, xgbMTrainHeadphone)
fwrite(importanceHeadphone, "importanceHeadphone.csv")
# CLEAN FORMAT
xgbImpVarClean <- function(input){
importance_clean <- input[,`:=`(Cover=NULL, Frequency=NULL)]
return(importance_clean)
}
importanceHeadphone <- xgbImpVarClean(importanceHeadphone)
# PLOT IMPORTANCE
xgbPlot <- function(input, var){
xgb.ggplot.importance(importance_matrix = input, top_n = 20) +
# ggtitle(paste("Feature Importance for", var, sep=" ")) +
theme(text = element_text(size = 12, family = "LM Roman 10"))
}
xgbPlot(importanceHeadphone, "Headphone")
dev.off()
png("8_FeatureVerificationHeadphones.png", res = 300, units="in", width=7, height=4)
xgbPlot(importanceHeadphone, "Headphone")
importanceCellphone <- fread("importanceCellphone.csv")
fwrite(importanceHeadphone, "importanceHeadphoneClean.csv")
importanceCellphone <- fread("importanceCellphone.csv")
importanceCellphone
# Apply xgbImpVarClean-function
importanceCellphone <- xgbImpVarClean(importanceCellphone)
importanceCellphone
importanceCellphone
# CLEAN FORMAT
xgbImpVarClean <- function(input){
importance_clean <- input[,`:=`(Cover=NULL, Frequency=NULL)]
return(importance_clean)
}
# Apply xgbImpVarClean-function
importanceCellphone <- xgbImpVarClean(importanceCellphone)
rm(list=ls())
importanceCellphone <- fread("importanceHeadphone.csv")
# PLOT IMPORTANCE
xgbPlot <- function(input, var){
xgb.ggplot.importance(importance_matrix = input, top_n = 20) +
# ggtitle(paste("Feature Importance for", var, sep=" ")) +
theme(text = element_text(size = 12, family = "LM Roman 10"))
}
xgbPlot(importanceHeadphone, "Headphone")
importanceHeadphone <- fread("importanceHeadphone.csv")
# PLOT IMPORTANCE
xgbPlot <- function(input, var){
xgb.ggplot.importance(importance_matrix = input, top_n = 20) +
# ggtitle(paste("Feature Importance for", var, sep=" ")) +
theme(text = element_text(size = 12, family = "LM Roman 10"))
}
xgbPlot(importanceHeadphone, "Headphone")
png("8_FeatureVerificationHeadphones.png", res = 300, units="in", width=7, height=4)
xgbPlot(importanceHeadphone, "Headphone")
dev.off()
importanceCellphone <- fread("importanceCellphone.csv")
# CLEAN FORMAT
xgbImpVarClean <- function(input){
importance_clean <- input[,`:=`(Cover=NULL, Frequency=NULL)]
return(importance_clean)
}
# Apply xgbImpVarClean-function
importanceCellphone <- xgbImpVarClean(importanceCellphone)
importanceCellphone <- as.data.table(importanceCellphone)
# CLEAN FORMAT
xgbImpVarClean <- function(input){
importance_clean <- input[,`:=`(Cover=NULL, Frequency=NULL)]
return(importance_clean)
}
# Apply xgbImpVarClean-function
importanceCellphone <- xgbImpVarClean(importanceCellphone)
View(importanceCellphone)
prep_cellphone_brand <- as_tibble(fread("output/prep_cellphone_brand.csv"))
prep_headphone_brand  <- as_tibble(fread("output/prep_headphone_brand.csv"))
prep_toaster_brand  <- as_tibble(fread("output/prep_toaster_brand.csv"))
prep_coffee_brand <- as_tibble(fread("output/prep_coffee_brand.csv"))
library(dplyr)
library(ggplot2)
library(tidyr) # spread/gather/separate
library(tidytext) # unnest_tokens
# TOKENIZE THE INPUT DATA INTO BIGRAMS
tokenizeBigrams <- function(input) {
input %>%
# n = 2 means bigram
unnest_tokens(bigram, review, token = "ngrams", n = 2)
}
# Apply tokenizeBigrams-function
tokenized_headphone_bigram <- tokenizeBigrams(prep_headphone_brand)
tokenized_toaster_bigram <- tokenizeBigrams(prep_toaster_brand)
tokenized_cellphone_bigram <- tokenizeBigrams(prep_cellphone_brand)
tokenized_coffee_bigram <- tokenizeBigrams(prep_coffee_brand)
# SEPARATE BIGRAMS
# to be able to filter out the stopwords
separateBigrams <- function(input) {
input %>%
separate(bigram, c("w1", "w2"), sep = " ")
}
# Apply separateBigrams-function
tokenized_cellphone_bigram <- separateBigrams(tokenized_cellphone_bigram)
tokenized_toaster_bigram <- separateBigrams(tokenized_toaster_bigram)
tokenized_coffee_bigram <- separateBigrams(tokenized_coffee_bigram)
tokenized_headphone_bigram <- separateBigrams(tokenized_headphone_bigram)
# REMOVE STOPWORDS FROM BIGRAMS
filterBigrams <- function(input) {
input %>%
filter(!w1 %in% stop_words$word) %>%
filter(!w2 %in% stop_words$word)
}
# Apply filterBigrams-function
tokenized_headphone_bigram_filtered <- filterBigrams(tokenized_headphone_bigram)
tokenized_cellphone_bigram_filtered <- filterBigrams(tokenized_cellphone_bigram)
tokenized_coffee_bigram_filtered <- filterBigrams(tokenized_coffee_bigram)
tokenized_toaster_bigram_filtered <- filterBigrams(tokenized_toaster_bigram)
# UNITE THE WORDS / GLUE BACK TOGETHER
uniteBigrams <- function(input) {
input %>% unite(bigram, w1, w2, sep = " ")
}
# Apply uniteBigrams-function
tokenized_headphone_bigram_united <- uniteBigrams(tokenized_headphone_bigram_filtered)
tokenized_cellphone_bigram_united <- uniteBigrams(tokenized_cellphone_bigram_filtered)
tokenized_coffee_bigram_united <- uniteBigrams(tokenized_coffee_bigram_filtered)
tokenized_toaster_bigram_united <- uniteBigrams(tokenized_toaster_bigram_filtered)
# COUNTING WITHOUT STOPWORDS
# Apply countBigram-function again
countBigramCellphone <- countBigram(tokenized_cellphone_bigram_united)
countBigramHeadphone <- countBigram(tokenized_headphone_bigram_united)
countBigramToaster <- countBigram(tokenized_toaster_bigram_united)
countBigramCoffee <- countBigram(tokenized_coffee_bigram_united)
# FILTER FOR NEGATIONS
# Unfiltered dataset has to be used (with stopwords)
filterBigramNot <- function(input) {
input %>%
filter(w1 == "not") %>%
filter(!w2 %in% stop_words$word) %>%
count(w1, w2, sort = TRUE)
}
# Apply filterBigramNot-function
filterBigramNotCellphone <- filterBigramNot(tokenized_cellphone_bigram)
filterBigramNotCoffee <- filterBigramNot(tokenized_coffee_bigram)
filterBigramNotToaster <- filterBigramNot(tokenized_toaster_bigram)
filterBigramNotHeadphone <- filterBigramNot(tokenized_headphone_bigram)
# PLOT NEGATED TERMS, PRECEDED BY A "NOT"
plotNotWords <- function(input, text, selectBrand) {
if(selectBrand != "") { # if wanted, brand
bigrams <- input %>% filter(brand == selectBrand)
bigrams <- bigrams %>%
unnest_tokens(bigram, review, token = "ngrams", n = 2)
} else {
bigrams <- input %>%
unnest_tokens(bigram, review, token = "ngrams", n = 2)
}
category <- rep("cat", nrow(bigrams))
bigrams$cat <- category
bigrams %>%
count(cat, bigram, sort = TRUE) %>%
ungroup() %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% c("not")) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
mutate(contribution = score * nn) %>%
group_by(word1) %>%
top_n(10, abs(contribution)) %>%
ungroup() %>%
mutate(word2 = reorder(paste(word2, word1, sep = "__"), contribution)) %>%
ggplot(aes(word2, contribution, fill = contribution > 0)) +
geom_col(show.legend = FALSE) +
scale_fill_manual(values=c( "firebrick", "dodgerblue4")) +
scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
xlab("Terms preceded by \"not\"") +
ylab("Sentiment Score * TF") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
coord_flip() +
#ggtitle(paste("Negate-Words for", text, sep = " ")) +
theme(text = element_text(size = 15, family = "LM Roman 10")) # Latex Font
}
# Apply plotNotWords-function
plotNotWords(prep_headphone_brand, "Headphones", "")
plotNotWords(prep_cellphone_brand, "Cellphones", "")
plotNotWords(prep_toaster_brand, "Toasters", "")
plotNotWords(prep_coffee_brand, "Coffee", "")
plotNotWords(prep_headphone_brand, "Headphones", "")
png("1.png", res = 300, units="in", width=7, height=4)
plotNotWords(prep_headphone_brand, "Headphones", "")
dev.off()
# Apply plotNotWords-function
png("1.png", res = 300, units="in", width = 6, height = 4)
plotNotWords(prep_headphone_brand, "Headphones", "")
dev.off()
# Apply plotNotWords-function
png("2.png", res = 300, units="in", width = 6, height = 4)
plotNotWords(prep_cellphone_brand, "Cellphones", "")
dev.off()
# Apply plotNotWords-function
png("3.png", res = 300, units="in", width = 6, height = 4)
plotNotWords(prep_toaster_brand, "Toasters", "")
dev.off()
# Apply plotNotWords-function
png("4.png", res = 300, units="in", width = 6, height = 4)
plotNotWords(prep_coffee_brand, "Coffee", "")
dev.off()
rm(list=ls())
